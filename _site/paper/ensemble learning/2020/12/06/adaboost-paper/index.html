
<!doctype html>














<html class="theme-next muse use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/assets/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/assets/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/assets/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="anogan," />





  <link rel="alternate" href="/atom.xml" title="Sanghoon's Blog" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/assets/favicon.ico?v=5.1.1" />
















<meta name="description" content="논문 선정 강필성 교수님의 비즈니스 어낼리틱스 수업의 네번째 논문 구현 주제는 Ensemble Learning이다. Boosting Algorihtm 기반의 방법론을 깊게 공부해보고자 가장 초기의 Boosting Algorihtm 중 하나인 Adaptive Boosting을 다룬 논문을 선정하였다. Adaptive Boosting의 줄임말인 AdaBoost는 1996년에 Freund와 Schapire이 제안한 알고리즘으로 2003년에는 괴델상을 수상한 알고리즘이기도 하다.">
<meta name="keywords" content="anogan">
<meta property="og:type" content="article">
<meta property="og:title" content="A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting">
<meta property="og:url" content="http://localhost:4000/paper/ensemble%20learning/2020/12/06/adaboost-paper/">
<meta property="og:site_name" content="Sanghoon's Blog">
<meta property="og:description" content="논문 선정 강필성 교수님의 비즈니스 어낼리틱스 수업의 네번째 논문 구현 주제는 Ensemble Learning이다. Boosting Algorihtm 기반의 방법론을 깊게 공부해보고자 가장 초기의 Boosting Algorihtm 중 하나인 Adaptive Boosting을 다룬 논문을 선정하였다. Adaptive Boosting의 줄임말인 AdaBoost는 1996년에 Freund와 Schapire이 제안한 알고리즘으로 2003년에는 괴델상을 수상한 알고리즘이기도 하다.">
<meta property="og:locale" content="en">
<meta property="og:image" content="/assets/figures/adaboost/adaboost.png">
<meta property="og:image" content="/assets/figures/adaboost/adaboost2.png">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting">
<meta name="twitter:description" content="논문 선정 강필성 교수님의 비즈니스 어낼리틱스 수업의 네번째 논문 구현 주제는 Ensemble Learning이다. Boosting Algorihtm 기반의 방법론을 깊게 공부해보고자 가장 초기의 Boosting Algorihtm 중 하나인 Adaptive Boosting을 다룬 논문을 선정하였다. Adaptive Boosting의 줄임말인 AdaBoost는 1996년에 Freund와 Schapire이 제안한 알고리즘으로 2003년에는 괴델상을 수상한 알고리즘이기도 하다.">
<meta name="twitter:image" content="/assets/figures/adaboost/adaboost.png">


<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://localhost:4000/"/>





  <title>A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting | Sanghoon's Blog</title>
  




<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'G-XWS5Q99M4Y', 'auto');
  ga('send', 'pageview');
</script>













</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"> <div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Sanghoon's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        
        
        <li class="menu-item menu-item-sitemap">
          <a href="/navigator/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-sitemap"></i> <br />
            
            Sitemap
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            <script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


<div id="posts" class="posts-expand">
  
  

  

  
  
  

  <article class="post post-type- " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://localhost:4000/paper/ensemble%20learning/2020/12/06/adaboost-paper/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Sanghoon Kim">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="assets/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sanghoon's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
          
          
            A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting
          
        </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-12-06T12:30:00+09:00">
                2020-12-06
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/category/#/paper" itemprop="url" rel="index">
                    <span itemprop="name">paper</span>
                  </a>
                </span>

                
                
                  , 
                
              
                
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/category/#/ensemble%20learning" itemprop="url" rel="index">
                    <span itemprop="name">ensemble learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          
            
                <div class="post-description">
                    
                </div>
            
          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="논문-선정">논문 선정</h2>
<p>강필성 교수님의 비즈니스 어낼리틱스 수업의 네번째 논문 구현 주제는 <strong>Ensemble Learning</strong>이다. Boosting Algorihtm 기반의 방법론을 깊게 공부해보고자 
가장 초기의 Boosting Algorihtm 중 하나인 Adaptive Boosting을 다룬 논문을 선정하였다. Adaptive Boosting의 줄임말인 AdaBoost는 1996년에 Freund와 Schapire이 제안한 알고리즘으로 
2003년에는 괴델상을 수상한 알고리즘이기도 하다.
<br /></p>

<div align="center">
<img src="/assets/figures/adaboost/adaboost.png" title="A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting" width="600" />
</div>

<blockquote>
  <p>Freund, Y., &amp; Schapire, R. E. (1997). A decision-theoretic generalization of on-line learning and an application to boosting. Journal of computer and system sciences, 55(1), 119-139.</p>
</blockquote>

<h2 id="adaboost">AdaBoost</h2>
<p>“Adaptive Boosting”의 약자 인 AdaBoost는 1996년 Freund와 Schapire가 제안한 최초의 실용적인 부스팅 알고리즘이다. 
AdaBoost의 목표를 간략히 말하면 약한 분류기를 강력한 분류기로 변환하는 것이라 할 수 있다. 즉, AdaBoost의 분류를 위한 최종 방정식을 살펴보면 다음과 같다.</p>

\[F(x)=sign(\sum_{m=1}^{M}\theta_m f_m(x))\]

<p>위의 식에서 \(f_m(x)\)는 총 \(M\)개의 개별 약한 분류기들을 나타내고 개별 가중치 \(\theta_m\)을 반영하여 가중합을 분류를 위한 최종 방정식(최종 강한 분류기)를 구축한다.</p>

<h2 id="adaboost-algorithm">AdaBoost algorithm</h2>
<p>AdaBoost 알고리즘의 전체 과정은 다음과 같이 요약할 수 있다.
먼저 n개의 데이터 포인트로 구성된 데이터 세트가 주어지면 각각의 데이터 포인트 \(x_i\)에 대하여 레이블 \(y_i\)를 
-1은 negative class를 나타내고 1은 positive class를 나타내도록 구성할 수 있다.</p>

\[x_i \in \mathbb{R}^d, y_i \in \{-1,1\}\]

<p>다음으로 각 데이터 포인트에 대한 가중치는 다음과 같이 초기화한다.</p>

\[w(x_i,y_i)= \frac{1}{n}, i=1,\ldots,n\]

<p>이후, 총 \(M\)개의 약한 분류기에 대해 아래의 과정을 수행한다.</p>

<p>(1) 각 m번째 시행마다 약한 분류기(ex. Decision Tree)를 데이터 세트로 한번 학습시킨 뒤에 분류 오류를 계산한다.</p>

\[\epsilon_m = E_{w_m}[1_{y \neq f(x)}]\]

<p>(2) m번째 약한 분류기의 개별 가중치 \(\theta_m\)을 다음의 식에 따라 계산한다.</p>

\[\theta_m=\frac{1}{2}ln(\frac{1-\epsilon_m}{\epsilon_m})\]

<p>이때, (2)의 개별 가중치 계산식에 따라 분류 정확도가 50% 이상인 경우 가중치는 양수가 되고 각 개별 분류기가 정확할수록 가중치가 커진다. 
반대로 정확도가 50% 미만인 분류기의 경우 가중치는 음수가 되는데 이는 정확도가 50% 미만인 경우 음의 가중치로서 최종 예측에 반영이 됨을 의미한다.
즉, 50% 정확도를 가진 분류기는 아무런 정보를 추가하지 않으므로 최종 예측에 영향을 주지 않는 반면, 정확도가 40%인 분류기는 음의 가중치로 페널티를 가지면서 최종 예측에 기여하게 된다.</p>

<p>(3) 다음으로 각 데이터별 가중치를 업데이트 한다.</p>

\[w_{m+1}(x_i,y_i)=\frac{w_m(x_i,y_i)exp[-\theta_m y_i f_m(x_i)]}{Z_m}\]

<p>이 때 \(Z_m\)은 모든 데이터별 가중치의 총합이 1이 되도록하는 Normalization Factor이다.</p>

<p>위 식을 살펴보면 분류기가 잘못 분류한 데이터 포인트의 경우, 분자에서 지수항(\(exp[-\theta_m y_i f_m(x_i)]\))이 항상 1보다 크게 된다.</p>

\[\because y_i f_m(x_i)=-1 \, \And \, \theta_m\ge0\]

<p>따라서 잘못 분류한 데이터 포인트는 (3)의 과정을 거치고 나면 더 큰 가중치로 업데이트된다. 이 (1)~(3)의 과정을 \(M\)개의 약한 분류기에 대해 모두 수행한 뒤, 각 분류기의 가중합을 통해 최종 예측을 얻는다.</p>

\[F(x)=sign(\sum_{m=1}^{M}\theta_m f_m(x))\]

<h2 id="additive-logistic-regression-a-statistical-view-of-boosting">Additive Logistic Regression: A Statistical View of Boosting</h2>
<p>다음으로 2000년에 Friedman 등이 AdaBoost algorithm을 통계적 관점에서 개선한 논문을 소개한다. 이 논문에서는 AdaBoost를 활용하여 단계적 추정을 통해 최종 로지스틱 회귀 모델을 맞추었다. 
즉 AdaBoost가 실제로 손실함수를 최소화하고 있음을 보여주었다.
<br /></p>

<div align="center">
<img src="/assets/figures/adaboost/adaboost2.png" title="Additive Logistic Regression: A Statistical View of Boosting" width="600" />
</div>
<p>``</p>

<p>손실함수는 다음과 같이 표현할 수 있는데,</p>

\[L(y, F(x))=E(e^{-yF(x)})\]

<p>이는 아래와 같은 포인트에서 최소화된다.</p>

\[\frac{\partial E(e^{-yF(x)})}{\partial F(x)}=0\]

<p>AdaBoost의 경우 \(y\)는 -1 또는 1만 될 수 있으므로 손실 함수는 다음과 같이 다시 작성할 수 있다.</p>

\[E(e^{-yF(x)})=e^{F(x)}P(y=-1|x)+e^{-F(x)}P(y=1|x)\]

<p>이를 \(F(x)\)에 대해 풀면, 아래와 같이 계산된다.</p>

\[\frac{\partial E(e^{-yF(x)})}{\partial F(x)}=e^{F(x)}P(y=-1|x)-e^{-F(x)}P(y=1|x)=0\]

\[F(x)=\frac{1}{2}\log{\frac{P(y=1|x)}{P(y=-1|x)}}\]

<p>또한 이 \(F(x)\)의 최적해로부터 로지스틱 모델을 유도할 수 있다.</p>

\[P(y=-1|x)=\frac{e^{2F(x)}}{1+e^{2F(x)}}\]

<p>만일 현재 추정치 \(F(x)\)와 개선된 추정치 \(F(x)+cf(x)\)가 있다면 고정된 \(x\)와 \(c\)에 대해 \(f(x)=0\)에 대한 2차식 \(L(y,F(x)+cf(X))\)을 얻을 수 있다.</p>

\[L(y,F(x)+cf(X))=E(e^{-y(F(x)+cf(x))})\]

\[\approx E(e^{-yF(x)}(1-ycf(x)+(cyf(x))^2/2)))\]

\[=E(e^{-yF(x)}(1-ycf(x)+c^2/2))\]

\[\therefore f(x)=\mathit{argmin}_f E_w(1-ycf(x)+c^2/2|x)\]

<p>이때 \(E_w(1-ycf(x)+c^2/2 \mid x)\)는 가중된 조건부 기대값을 나타내며 각 데이터 포인트에 대한 가중치는 다음과 같이 계산된다.</p>

\[w(x_i,y_i)= e^{-y_i F(x_i)}, i=1,\ldots,n\]

<p>만약 \(c\)가 양수라면 가중된 조건부 기대값을 최소화하는 것은 \(E_w[yf(x)]\)를 최대화하는 것과 같다.
또한 \(y\)는 1 또는 -1의 값만 가질 수 있으므로 \(E_w[yf(x)]\)는 아래와 같이 쓸 수 있다.</p>

\[E_w[yf(x)]=f(x)P_w(y=1|x)-f(x)P_w(y=-1|x)\]

\[f(n)= \begin{cases}
1, &amp; \mbox{if } P_w(y=1|x)&gt;P_w(y=-1|x) \\
-1, &amp; \mbox{if }\mbox{ otherwise.}
\end{cases}\]

<p>이렇게 \(f(x)\)를 결정한 후 가중치 \(c\)는 \(L(y, F(x) + cf(x))\)를 직접 최소화하여 계산할 수 있다.</p>

\[c=\mathit{argmin}_c E_w(e^{-cyf(x)})\]

\[\frac{\partial E(e^{-cyf(x)}}{\partial c}=E_w(-yf(x)e^{-cyf(x)})=0\]

\[E_w(1_{y \neq f(x)})e^c-E_w(1_{y=f(x)})e^{-c}\]

<p>\(\epsilon\)을 잘못 분류된 케이스들의 가중합과 같이 두면,</p>

\[\epsilon e^{c}-(1-\epsilon)e^{-c}=0\]

\[c=\frac{1}{2}\log{\frac{1-\epsilon}{\epsilon}}\]

<p>즉, 약한 분류기의 정확도가 50% 미만일 경우 c는 음수가 된다.
또한 모델의 개선 후(\(F(x)+cf(x)\)) 각 개별 데이터 포인트에 대한 가중치는 다음과  같다.</p>

\[w(x_i,y_i)= e^{-y_i F(x_i)-c y_i f(x)}, i=1,\ldots,n\]

<p>그러므로 각 데이터별 가중치는 다음과 같이 업데이트 된다.</p>

\[w(x_i,y_i) \leftarrow w(x_i,y_i)e^{-cf(x_i)y_i}\]

<p>이는 위에서 살펴본 AdaBoost Algorithm과 동일한 형태임을 알 수 있다. 따라서 AdaBoost를 지수 손실함수가 있는 모델의 각 반복 m에서 현재 추정치를 개선하기 위해 약한 분류기에 반복적으로 적합하여 
순방향 단계적 가산 모델로 해석하는 것이 합리적임을 알 수 있다.</p>

\[w_{m+1}(x_i,y_i)=\frac{w_m(x_i,y_i)exp[-\theta_m y_i f_m(x_i)]}{Z_m}\]

\[\theta_m=\frac{1}{2}ln(\frac{1-\epsilon_m}{\epsilon_m})\]

<h2 id="code">Code</h2>
<p>Code 수행은 iris 데이터의 분류 문제에 AdaBoost 모델을 적용했다. 데이터는 7:3의 비율로 학습과 테스트 데이터를 나누었다.</p>

<p>AdaBoost의 실제 활용에서는 다음과 같은 단계를 따른다.</p>
<ol>
  <li>처음에 학습데이터 중 일부를 추출한다.</li>
  <li>선택되지 않은 나머지 학습데이터로 평가를 진행하면서(Validation Set) 선택된 학습데이터로 AdaBoost 모델을 반복적으로 학습한다.</li>
  <li>모델이 잘못 분류한 관측치에 더 높은 가중치를 할당하여, 다음 반복에서 이러한 관측치가 높은 분류 확률을 얻도록 학습한다.</li>
  <li>분류기의 정확도에 따라 각 반복에서 훈련된 분류기에 가중치를 할당한다. 더 정확한 분류기는 높은 가중치를 가진다.</li>
  <li>이 프로세스는 최종 모델이 학습데이터에 대해 모두 오류없이 적합하거나 지정된 수의 분류기(n_estimators)를 구축할 때까지 반복한다.</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Load data
</span><span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="p">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="p">.</span><span class="n">target</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">adaboost_classifier</span> <span class="o">=</span> <span class="n">AdaBoostClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                         <span class="n">learning_rate</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>
<p>AdaBoost에서 가장 중요한 Hyper-parameter는 모델 훈련에 사용되는 약한 분류기인 base_estimator와 반복적으로 훈련할 약한 분류기의 수(\(M\))를 나타내는 n_estimators, 약한 분류기의 가중치에 기여하는 learning_rate이다. 
base_estimator, 즉 약한 분류기는 sklearn의 AdaBoost 모델의 default 설정 그대로 Decision Tree 모델을 사용하여 모델을 학습시킨 후, 이를 평가했다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Train Adaboost Classifer
</span><span class="n">model</span> <span class="o">=</span> <span class="n">adaboost_classifier</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1">#Predict the response for test dataset
</span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Evaluate Model
</span><span class="k">print</span><span class="p">(</span><span class="s">"Accuracy:"</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></div>
<p>그 결과 88.88%의 분류 정확도를 얻을 수 있었다.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Accuracy: 0.8888888888888888
</code></pre></div></div>
<p>다음으로 약한 분류기를 Support Vector Classifier로 활용한 뒤 최종 AdaBoost 모델을 구축했다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>

<span class="n">svc</span><span class="o">=</span><span class="n">SVC</span><span class="p">(</span><span class="n">probability</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s">'linear'</span><span class="p">)</span>
<span class="n">abc</span> <span class="o">=</span><span class="n">AdaBoostClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">base_estimator</span><span class="o">=</span><span class="n">svc</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Train Adaboost Classifer
</span><span class="n">model</span> <span class="o">=</span> <span class="n">abc</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1">#Predict the response for test dataset
</span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Model Accuracy, how often is the classifier correct?
</span><span class="k">print</span><span class="p">(</span><span class="s">"Accuracy:"</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></div>
<p>최종 AdaBoost 모델 구축 시 SVC를 약한 분류기(base estimator)로 활용했을 때 Decision Tree의 경우보다 Iris 데이터에 대하여 더 높은 성능을 보임을 알 수 있었다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Accuracy: 0.9555555555555556
</code></pre></div></div>
<h2 id="결론">결론</h2>
<p>이번 논문 구현 과제를 통해 AdaBoost 모델의 기본 개념을 숙지 할 수 있었다. 기본적으로 다양한 분류 모델들을 AdaBoost의 Base Estimator가 되는 약한 분류기로 사용할 수 있고 
이 약한 분류기의 실수를 반복적으로 수정하고 약한 분류기를 결합하여 정확도를 높이는 과정이기에 구현하기 쉬운 장점이 있다는 것을 알 수 있었다. 하지만 AdaBoost는 각 데이터 포인트에 완벽히 맞추려는
알고리즘의 특성상 outlier에 민감할 수 밖에 없다. 따라서 이러한 단점을 보완하는 Boosting 계열의 후속 연구들이 이어졌고 추후 나머지 알고리즘에 대해서도 공부해볼 계획이다.
추가적으로 데이터 사이즈가 클 경우 XGBoost에 비해 AdaBoost가 학습 속도가 느리다는 것을 이번 구현 과정에서 알 수 있었는데 학습 속도의 차이가 나타나는 정확한 이유에 대해서도 살펴볼 생각이다.</p>

<blockquote>
  <p><strong>참고문헌</strong></p>
  <ol>
    <li>Freund, Y., &amp; Schapire, R. E. (1997). A decision-theoretic generalization of on-line learning and an application to boosting. Journal of computer and system sciences, 55(1), 119-139.</li>
    <li>Friedman, J., Hastie, T., &amp; Tibshirani, R. (2000). Additive logistic regression: a statistical view of boosting (with discussion and a rejoinder by the authors). The annals of statistics, 28(2), 337-407.``</li>
  </ol>
</blockquote>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            
            <a href="/tag/#/anogan" rel="tag"># anogan</a>
          
        </div>
      

      
      
      
      
      

      
      
        <div class="post-nav" id="post-nav-id">
          <div class="post-nav-next post-nav-item">
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/paper/anomaly%20detection/2020/11/15/anogan-paper/" rel="prev" title="Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery">
                Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      
      

      
    </footer>
  </article>

  <div class="post-spread">
    
  </div>
</div>


<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = http://localhost:4000/paper/ensemble%20learning/2020/12/06/adaboost-paper/;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = /paper/ensemble%20learning/2020/12/06/adaboost-paper; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://october25kim.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          

  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      
        
        
        




      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/assets/images/avatar.gif"
               alt="Sanghoon Kim" />
          <p class="site-author-name" itemprop="name">Sanghoon Kim</p>
           
              <p class="site-description motion-element" itemprop="description">Study Record of Machine Learning, Deep Learning</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">4</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/">
                <span class="site-state-item-count">5</span>
                <span class="site-state-item-name">categories</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/">
                <span class="site-state-item-count">3</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        
        
        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            





            
              <div class="post-toc-content">
    <ol class=nav>
      <li class="nav-item nav-level-2"> <a class="nav-link" href="#논문-선정"> <span class="nav-number">1</span> <span class="nav-text">논문 선정</span> </a> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> </li></ol> </li></ol> </li></ol> </li></ol> </li> <li class="nav-item nav-level-2"> <a class="nav-link" href="#adaboost"> <span class="nav-number">2</span> <span class="nav-text">AdaBoost</span> </a> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> </li></ol> </li></ol> </li></ol> </li></ol> </li> <li class="nav-item nav-level-2"> <a class="nav-link" href="#adaboost-algorithm"> <span class="nav-number">3</span> <span class="nav-text">AdaBoost algorithm</span> </a> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> </li></ol> </li></ol> </li></ol> </li></ol> </li> <li class="nav-item nav-level-2"> <a class="nav-link" href="#additive-logistic-regression-a-statistical-view-of-boosting"> <span class="nav-number">4</span> <span class="nav-text">Additive Logistic Regression: A Statistical View of Boosting</span> </a> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> </li></ol> </li></ol> </li></ol> </li></ol> </li> <li class="nav-item nav-level-2"> <a class="nav-link" href="#code"> <span class="nav-number">5</span> <span class="nav-text">Code</span> </a> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> </li></ol> </li></ol> </li></ol> </li></ol> </li> <li class="nav-item nav-level-2"> <a class="nav-link" href="#결론"> <span class="nav-number">6</span> <span class="nav-text">결론</span> </a> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child">
    </ol>
  </div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>

        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Sanghoon Kim</span>
</div>


<div class="powered-by">
  Powered by <a class="theme-link" href="https://jekyllrb.com">Jekyll</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/simpleyyt/jekyll-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>





















  
   
  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/jquery/index.js?v=2.1.3"></script>

  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/assets/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/assets/js/src/motion.js?v=5.1.1"></script>



  
  

  <script type="text/javascript" src="/assets/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/assets/js/src/post-details.js?v=5.1.1"></script>


  


  <script type="text/javascript" src="/assets/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  




  

    

  





  






  

  

  
  


  
  


  

  

</body>
</html>

